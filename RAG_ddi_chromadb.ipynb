{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e33267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be991758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your JSON data\n",
    "with open(\"prompt.json\") as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d1e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract prompts and completions\n",
    "prompts = [entry['prompt'] for entry in data]\n",
    "completions = [entry['completion'] for entry in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cc1d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer and model for embeddings\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5529d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get embeddings for text\n",
    "def get_embeddings(texts):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8827880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for prompts and completions\n",
    "prompt_embeddings = get_embeddings(prompts)\n",
    "completion_embeddings = get_embeddings(completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce28ec97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP NOTES\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Chroma DB client\n",
    "client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0948cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single collection for both prompts and completions\n",
    "collection = client.create_collection(\"prompt_completion_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d749a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    ids=[f\"prompt_{i}\" for i in range(len(data))],  # Assigning unique IDs like 'prompt_1', 'prompt_2', etc.\n",
    "    documents=prompts,  # Adding prompt texts\n",
    "    embeddings=prompt_embeddings.numpy().tolist(),\n",
    "    metadatas=[{\"type\": \"prompt\", \"id\": f\"prompt_{i}\"} for i in range(len(data))]  # Metadata with 'type' and 'id'\n",
    ")\n",
    "\n",
    "collection.add(\n",
    "    ids=[f\"completion_{i}\" for i in range(len(data))],  # Similarly, assign unique IDs for completions\n",
    "    documents=completions,  # Adding completion texts\n",
    "    embeddings=completion_embeddings.numpy().tolist(),\n",
    "    metadatas=[{\"type\": \"completion\", \"id\": f\"completion_{i}\"} for i in range(len(data))]  # Metadata with 'type' and 'id'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97aec2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Document (Completion):\n",
      "Document: risk or severity of bleeding\n",
      "Metadata: {'id': 'completion_1', 'type': 'completion'}\n",
      "Retrieved Document (Completion):\n",
      "Document: What is the interaction between Bivalirudin and Acemetacin?\n",
      "Metadata: {'id': 'prompt_1', 'type': 'prompt'}\n"
     ]
    }
   ],
   "source": [
    "# Function to query the prompt_completion_collection for a prompt and return the related completion\n",
    "def query_prompt_for_completion(query, collection, top_k=3):\n",
    "    # Generate the embedding for the query (the prompt)\n",
    "    query_embedding = get_embeddings([query])\n",
    "    \n",
    "    # Query the collection to find the most similar prompt\n",
    "    results = collection.query(query_embeddings=query_embedding.numpy().tolist(), n_results=1)\n",
    "    \n",
    "    # Initialize an empty list to store completions\n",
    "    completions = []\n",
    "    \n",
    "    # Process each result (document and metadata)\n",
    "    for result, metadata in zip(results['documents'], results['metadatas']):\n",
    "        print(\"Result:\", result)  # Print the result (document)\n",
    "        print(\"Metadata:\", metadata)  # Print metadata to check its structure\n",
    "        \n",
    "        # Check if the metadata is a list (it might be a list of dicts)\n",
    "        if isinstance(metadata, list):\n",
    "            # Iterate through the metadata list and look for the prompt type\n",
    "            for item in metadata:\n",
    "                if item.get('type') == 'prompt':  # If it's a prompt\n",
    "                    # Extract the index i from the prompt_id (e.g., prompt_1 -> i = 1)\n",
    "                    prompt_id = item.get('id', '')  # Fetch ID if it exists\n",
    "                    if prompt_id: \n",
    "                        index = int(prompt_id.split('_')[1])  # Extract index from 'prompt_i'\n",
    "                        # Fetch the corresponding completion based on the same index i\n",
    "                        completion_id = f\"completion_{index}\"  # corresponding completion_id\n",
    "                        # Retrieve the corresponding completion from the collection\n",
    "                        completion = collection.get(ids=[completion_id])  # Fetch the completion\n",
    "                        # Append the retrieved completion text to the completions list\n",
    "                        completions.append(completion['documents'][0])  # Assuming one result for the ID\n",
    "                        break  # Once found, no need to check other metadata items\n",
    "        else:\n",
    "            # Handle non-list metadata\n",
    "            if metadata.get('type') == 'prompt':  # Handle case where metadata is not a list\n",
    "                prompt_id = metadata.get('id', '')\n",
    "                if prompt_id:\n",
    "                    index = int(prompt_id.split('_')[1])  # Extract index from 'prompt_i'\n",
    "                    completion_id = f\"completion_{index}\"\n",
    "                    completion = collection.get(ids=[completion_id])  # Fetch the completion\n",
    "                    completions.append(completion['documents'][0])  # Assuming one result for the ID\n",
    "    \n",
    "    return completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ad3b7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: ['What is the interaction between Bivalirudin and Acemetacin?']\n",
      "Metadata: [{'id': 'prompt_1', 'type': 'prompt'}]\n",
      "Retrieved Completions (Answers):\n",
      "risk or severity of bleeding\n"
     ]
    }
   ],
   "source": [
    "# Example query to search for the related completion\n",
    "query = \"What is the interaction between Bivalirudin and Acemetacin?\"\n",
    "completion_results = query_prompt_for_completion(query, collection)\n",
    "\n",
    "# Print the retrieved completions (answers)\n",
    "print(\"Retrieved Completions (Answers):\")\n",
    "for result in completion_results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6da77336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: ['What is the interaction between Bivalirudin and Acemetacin?']\n",
      "Metadata: [{'id': 'prompt_1', 'type': 'prompt'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP NOTES\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\question_answering.py:391: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Answer:\n",
      "risk or severity of bleeding\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the question-answering pipeline with a pre-trained model\n",
    "qa_model = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
    "\n",
    "# Function to generate an answer using the QA model\n",
    "def generate_answer(query, context):\n",
    "    qa_input = {\n",
    "        \"question\": query,\n",
    "        \"context\": context\n",
    "    }\n",
    "    # Get the result from the model\n",
    "    result = qa_model(qa_input)\n",
    "    return result['answer']\n",
    "\n",
    "# Example query to search for the related completion\n",
    "query = \"What is the interaction between Bivalirudin and Acemetacin?\"\n",
    "\n",
    "# Retrieve the completion(s) corresponding to the prompt (this part assumes you've already fetched the completion)\n",
    "completion_results = query_prompt_for_completion(query, collection)\n",
    "\n",
    "# Combine the retrieved completions into context\n",
    "context = \" \".join(completion_results)  # Combine completions into the context for QA\n",
    "\n",
    "# Generate the answer based on the context\n",
    "answer = generate_answer(query, context)\n",
    "\n",
    "# Print the generated answer\n",
    "print(\"\\nGenerated Answer:\")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a65489c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
